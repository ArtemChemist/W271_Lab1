---
title: "W271 Group Lab 1"
subtitle: "Investigating the 1986 Space Shuttle Challenger Accident"
author: "Please fill in with your names."
output: bookdown::pdf_document2
fontsize: 11pt
geometry: margin=1in
---

\newpagecool

```{=tex}
\begin{abstract} 
This report will, indeed, be abstract. No, instead, describe your goals your approach, and what you learn.
\end{abstract}

```
# Introduction

## Research question
```{r load packages, message=FALSE}
library(car)
library(sandwich)
library(lmtest)
library(knitr)
library(Hmisc)
library(gridExtra)
library(stargazer)
library(mcprofile)
library(readr)
library(dplyr)
library(finalfit)
```

# Data (20 points)

**Complete the following task. In your final submission, please remove this question prompt so that your report reads as a report. The Data Section of this report is worth 20 points.**

-   Conduct a thorough EDA of the data set.

    -   This should include both graphical and tabular analysis as taught in this course.
    -   Since the report has a page-limit, you will have to be selective when choosing visuals to illustrate your key points, associated with a concise explanation of the visuals.

-   This EDA should begin with an inspection of the given dataset; examination of anomalies, missing values, potential of top and/or bottom code etc.

```{r}
data <- read.csv("../data/raw/challenger.csv")
data
```


```{r}
summary(data)
```

```{r}
describe(data)
```

```{r}
# Histograms
hist(data$Temp, main="Joint Temperature Distribution", xlab="Temp")
hist(data$Pressure, main="Field Leak-Pressure Distribution", xlab="Pressure")
```

```{r}
# Define colors based on O.ring values
color <- ifelse(data$O.ring > 0, "red", "green")

# Create the scatter plot
plot(data$Temp, data$O.ring, xlab = "Temperature", ylab = "O-ring", main = "Temperature vs. O-ring", pch = 19, col = color)
# Create a legend
legend("topright", legend = c("Flights with no incidents", "Number of Incidents"), col = c("green", "red"), pch = 19)

```

```{r}
data %>%
  count(O.ring) %>%
  mutate(prop = round(prop.table(n),2)) %>%
  kable(col.names = c('Incidents', 'Number', "Proportion"))
```

```{r}
plot_box = function(data,x,y,title) {
  ggplot(data, aes(factor(x), y)) +  
  geom_boxplot(aes(fill = factor(x))) + 
  geom_jitter() +
  coord_flip() +
  ggtitle(title) + 
  theme(plot.title = element_text(lineheight=1, face="bold")) 
}

# Admit and GRE
p3 <- plot_box(data, x=data$O.ring, y=data$Temp,
               title="Figure 1: O-ring incident by Temperature")

# Admit and GPA
p4 <- plot_box(data, x=data$O.ring, y=data$Pressure, 
               title="Figure 2: O-ring incident by Pressure")

grid.arrange(p3, p4, nrow = 2, ncol = 1)


```
```{r}
data
```


## Description

**Complete the following task. In your final submission, please remove this question prompt so that your report reads as a report.**
 
-   Describe the data that you are using. How is this data generated, what is the sampling process that brought it to your availability. If it is helpful, you might describe the population (i.e. the Random Variables) that exist and how samples are produced from these random variables.

-   The authors use logistic regression to estimate the probability an O-ring will fail. In order to use this model, the authors needed to assume that each O-ring is independent for each launch. Discuss why this assumption is necessary and the potential problems with it. Note that a subsequent analysis helped to alleviate the authors' concerns about independence.

The data being used in this analysis pertains to the Challenger Space Shuttle disaster and was generated by recording observations across different shuttle launches. The observations include details about temperature, pressure, and O-ring failure during each of these launches.

The data can be understood as a sample from a population of all possible shuttle launches. The random variables in this context could be the temperature, pressure, and O-ring failure status, and the specific values we have for these variables from the actual launches are particular realizations of these random variables.

The sampling process in this case is not a random sampling process in the traditional sense because it doesn't involve randomly selecting elements from a larger population. Rather, it involves recording observations from a sequence of events (the shuttle launches) that actually took place. Each launch can be thought of as an experiment where the temperature and pressure are somewhat uncontrollable variables and the O-ring failure status is the outcome.

The assumption of independence in the context of logistic regression means that we assume the outcome (O-ring failure) of one launch doesn't affect the outcome of another launch. This is necessary because if the outcomes were dependent, it would complicate the model and the estimation of the parameters, and the usual logistic regression model wouldn't apply.

The potential problem with this assumption in the current context is that the launches are not truly independent events. Factors like technological advancements, changes in maintenance practices, and learning from past failures could cause later launches to be dependent on earlier ones. Additionally, the physical conditions of the O-rings might not be independent, for example, if the same set of O-rings were used in multiple launches.

## Key Features

Data Source and Context: The data set is derived from the Challenger Space Shuttle missions, detailing the conditions of each launch, particularly focusing on temperature, pressure, and the crucial aspect of O-ring failure. The observations represent specific shuttle launches under various conditions.

Variables: The primary variables in this data set include temperature (Temp), pressure (Pressure), and the status of the O-ring (O.ring). Each variable provides critical information about the conditions during each space shuttle launch.

Target Variable: The target variable in the analysis is O-ring failure, a binary variable that indicates whether an O-ring failure occurred during a launch (1 = failure, 0 = no failure).

Explanatory Variables: The temperature and pressure during each launch are the explanatory variables. These continuous variables provide context for the conditions that may influence O-ring failure.

Data Structure: The data set is structured as a cross-sectional data set, with each row representing a different space shuttle launch.

# Analysis

Temperature (Temp):

Distribution: The temperature during the launches varied from 53°F to 81°F. The distribution of temperature values was fairly normal but slightly skewed towards the higher end.

Relationship with O-ring failure: The exploratory data analysis and logistic regression model indicated a significant relationship between temperature and O-ring failure. Specifically, lower temperatures were associated with a higher risk of O-ring failure. This relationship was found to be statistically significant, making temperature a key variable to consider when predicting O-ring failure.

Insights: The fact that colder temperatures increase the risk of O-ring failure can have important practical implications. For example, it could inform decisions about the optimal conditions for launching a space shuttle to minimize the risk of O-ring failure.

Pressure (Pressure):

Distribution: The pressure during the launches was mostly around 200 psi, with a few instances of lower pressure at 50 psi and 100 psi. The distribution was therefore skewed towards the higher end.

Relationship with O-ring failure: The exploratory data analysis and logistic regression model did not indicate a statistically significant relationship between pressure and O-ring failure. Although pressure was initially included as an explanatory variable in the model, the likelihood ratio test suggested that it did not significantly improve the model's fit to the data.

Insights: While it might seem logical that higher pressure could increase the risk of O-ring failure, the data did not provide statistical evidence for this. Therefore, based on this data set, pressure does not appear to be a key variable to consider when predicting O-ring failure.

In conclusion, while both temperature and pressure are important factors in the overall operating conditions during a space shuttle launch, temperature appears to be the more crucial variable when it comes to predicting O-ring failure.


## Reproducing Previous Analysis (10 points)

**Your analysis should address the following two questions. In your final submission, please remove this question prompt so that your report reads as a report.**

1.  Estimate the logistic regression model that the authors present in their report -- include the variables as linear terms in the model. Evaluate, using likelihood ratio tests, the statistical significance of each explanatory variable in the model. Evaluate, using the context and data understanding that you have created in the **Data** section of this report, the practical significance of each explanatory variable in the model.


```{r}
# Check if O.ring is a factor, if not convert it
if (!is.factor(data$O.ring)) {
  data$O.ring <- as.factor(data$O.ring)
}

# Fit the logistic regression model
model <- glm(O.ring ~ Temp + Pressure, data = data, family = binomial(link = "logit"))

# Fit reduced models
model_temp <- glm(O.ring ~ Temp, data = data, family = binomial(link = "logit"))
model_pressure <- glm(O.ring ~ Pressure, data = data, family = binomial(link = "logit"))

summary(model)
```
The coefficient of -0.228671 indicates that for each additional degree in temperature, the log-odds of O-ring failure decrease by about 0.23, holding pressure constant. This would suggest that higher temperatures are associated with a lower risk of O-ring failure. Because the p-value (0.0376) is below 0.05, this result is statistically significant at the 5% level.

The coefficient of 0.010400 suggests that for each additional unit increase in pressure, the log-odds of O-ring failure increase by about 0.01, holding temperature constant. However, the p-value (0.2468) is greater than 0.05, suggesting that this result is not statistically significant at the 5% level. Therefore, based on this model, pressure does not have a significant effect on the log-odds of O-ring failure.

From a practical perspective, temperature seems to have a significant effect on O-ring failure, with higher temperatures reducing the likelihood of failure. However, pressure doesn't seem to significantly affect the likelihood of failure.

```{r}
# Perform likelihood ratio tests
anova(model_temp, model, test = "LRT")
```
The test compares the deviances of the two models to assess whether adding Pressure to the model significantly improves the model fit. The deviance difference (1.5331) is not statistically significant (p=0.2156), as indicated by the Pr(>Chi) value. This means that, based on this test, adding Pressure as a predictor does not significantly improve the model.

```{r}
anova(model_pressure, model, test = "LRT")
```
The test compares the deviances of the two models to assess whether adding Temp to the model significantly improves the model fit. The deviance difference (7.7542) is statistically significant (p=0.005359), as indicated by the Pr(>Chi) value. This means that adding Temp as a predictor significantly improves the model.

In summary, these results suggest that Temp is a significant predictor of O.ring failure, while Pressure is not, at least not when added to a model that already includes Temp.


```{r}
exp(coef(model))
```

The exponentiated coefficient for Temp is 0.7955903. This means that for each unit increase in Temp, the odds of O-ring failure are multiplied by approximately 0.80, or in other words, they decrease by about 20%, assuming all other variables are held constant. This matches with our previous interpretation that an increase in temperature decreases the likelihood of O-ring failure.

The exponentiated coefficient for Pressure is 1.010454. This means that for each unit increase in Pressure, the odds of O-ring failure are multiplied by approximately 1.01, or they increase by about 1%, assuming all other variables are held constant. However, remember from the earlier analysis that this effect was not statistically significant.


2.  Dalal, Fowlkes, and Hoadley (1989) chose to remove `pressure` from the model based on their likelihood ratio tests. Critically evaluate, using your test results and understanding of the question and data, whether `pressure` should be included in the model, or instead, `pressure` should not be included in the model. Your report needs to make a determination, argue why it is most appropriate choice, and make note of how (if at all) the model results are affected by the choice of including or excluding `pressure`.

Based on the likelihood ratio tests that we have conducted, we found that the inclusion of Pressure in the model does not significantly improve the model's fit when Temp is already in the model. This is indicated by a non-significant p-value (p = 0.2156) when we compared the model with Temp and Pressure to the model with Temp alone.

On the contrary, when we compared the model with Pressure alone to the model with Temp and Pressure, we observed a significant improvement in the model fit with the inclusion of Temp (p = 0.005359).

Taking these results together, it would be reasonable to exclude Pressure from the model. By doing so, we would have a simpler model that is easier to interpret, without a significant loss in predictive power.

Excluding Pressure from the model does not appear to negatively affect the model's ability to predict O-ring failure. The significant predictor, Temp, remains in the model and its coefficient remains statistically significant, indicating that it is still able to predict O-ring failure effectively.


## Confidence Intervals (20 points)

No matter what you determined about using or dropping `pressure`, for this section begin by considering the simplified model $logit(\pi) = \beta_0 + \beta_1 Temp$, where $\pi$ is the probability of an O-ring failure. Complete the following:

1.  Estimate the logistic regression model.

```{r}
model_temp <- glm(O.ring ~ Temp, family = binomial(link = "logit"), data = data)
coef(model_temp)
```

```{r}
data
```


2.  Determine if a quadratic term is needed in the model for the temperature in this model.

```{r}
model_temp_quad <- glm(O.ring ~ Temp + I(Temp^2), family = binomial(link = "logit"), data = data)
anova(model_temp, model_temp_quad, test = "Chisq")

```
Not needed.

3.  Construct two plots:
4.  $\pi$ vs. Temp; and,

```{r}
temp_range <- seq(31, 81, length.out = 100)

prob_est <- predict(model_temp, newdata = data.frame(Temp = temp_range), type = "response")
conf_int <- predict(model_temp, newdata = data.frame(Temp = temp_range), type = "link", se.fit = TRUE)

alpha = 0.05
CI.pred.upper = conf_int$fit + qnorm(0.95)*conf_int$se.fit
CI.pred.lower = conf_int$fit + qnorm(0.05)*conf_int$se.fit
CI.pi.upper = exp(CI.pred.upper)/(1+exp(CI.pred.upper))
CI.pi.lower = exp(CI.pred.lower)/(1+exp(CI.pred.lower))

plot(temp_range, prob_est, type = "l", xlab = "Temperature", ylab = "Probability of O-ring failure", col='red')
lines(temp_range, CI.pi.upper, lty = 2, col='blue')
lines(temp_range, CI.pi.lower, lty = 2, col='blue')
legend("bottomright", 
       legend = c("Confidence Interval", "Fitted Model"),  
       col = c("blue", "red"), 
       pch = c(20, NA),  
       lty = c(NA, 1),  
       cex = 0.8,  
       bty = "n", 
       lwd = c(NA, 2))
```

5.  Expected number of failures vs. Temp.

```{r}
expected_failures <- prob_est * 6  # Assuming there are 6 O-rings
plot(temp_range, expected_failures, type = "l", xlab = "Temperature", ylab = "Expected number of O-ring failures")
```

Specific requirements for these plots:

-   Use a temperature range of 31° to 81° on the x-axis even though the minimum temperature in the data set was 53°.\

-   Include the 95% Wald confidence interval bands for $\pi$ on the plot. Describe, in your analysis of these plots, why the bands much wider for lower temperatures than for higher temperatures?

3.  The temperature was 31° at launch for the Challenger in 1986. Estimate the probability of an O-ring failure using this temperature, and compute a corresponding confidence interval. Discuss what assumptions need to be made in order to apply the inference procedures.


```{r}

prob_31 <- predict(model_temp, newdata = data.frame(Temp = 31), type = "response")
conf_int_31 <- predict(model_temp, newdata = data.frame(Temp = 31), type = "link", se.fit = TRUE)
CI_31.pred.upper = conf_int_31$fit + qnorm(0.95)*conf_int_31$se.fit
CI_31.pred.lower = conf_int_31$fit + qnorm(0.05)*conf_int_31$se.fit
CI_31.pi.upper = exp(CI_31.pred.upper)/(1+exp(CI_31.pred.upper))
CI_31.pi.lower = exp(CI_31.pred.lower)/(1+exp(CI_31.pred.lower))

prob_31
CI_31.pi.upper
CI_31.pi.lower

```

## Bootstrap Confidence Intervals (30 points)

Rather than relying on asymptotic properties, consider using a parametric bootstrap, as did Dalal, Fowlkes and Hoadley. To do this:

1.  Simulate a large number of data sets (n = 23 for each) by re-sampling with replacement from the data.
2.  Estimate a model for each dataset.
3.  Compute the effect at a specific temperature of interest.

To produce a confidence interval, the authors used the 0.05 and 0.95 observed quantiles from the simulated distribution as their 90% confidence interval limits.

Using the parametric bootstrap, compute 90% confidence intervals separately at each integer temperature between 10° and 100° Fahrenheit.

In this section, you should describe your process, justify such a process, and present your results in a way that is compelling for your reader.

```{r}
# Load necessary library
library(MASS)

# Set seed for reproducibility
set.seed(123)

# Fit the initial model to the data
fit <- glm(O.ring ~ Temp, data = data, family = binomial)

# Extract the fitted parameters
alpha <- coef(fit)[1]
beta <- coef(fit)[2]

# Number of bootstrap resamples
R <- 1000

# Preallocate a matrix to store the bootstrap coefficients
bootstrap_coefs <- matrix(NA, nrow = R, ncol = 2,
                          dimnames = list(1:R, names(coef(fit))))

i <- 0
# Run the bootstrap
while (i < R) {
  # Generate new response values from the fitted model
  y_star <- rbinom(n = nrow(data), size = 1, prob = plogis(alpha + beta * data$Temp))
  
  # Fit the model to the new data
  fit_star <- glm(y_star ~ data$Temp, family = binomial)
  
  if (fit_star$deviance >0.1) {
  # Record the estimated parameters
  i = i+1
  bootstrap_coefs[i,] <- coef(fit_star)
  }
}

# Compute the 90% confidence interval for alpha
alpha_CI <- quantile(bootstrap_coefs[, "(Intercept)"], probs = c(0.05, 0.95))

# Preallocate a matrix for the beta confidence intervals
beta_CI <- matrix(NA, nrow = 91, ncol = 2, 
                  dimnames = list(10:100, c("Lower", "Upper")))

# Compute the 90% confidence interval for beta at each temperature
for (temp in 10:100) {
  # Calculate the beta values at this temperature
  beta_at_temp <- alpha_CI + bootstrap_coefs[, "Temp"] * temp
  # Compute the confidence interval
  beta_CI[temp - 9,] <- quantile(beta_at_temp, probs = c(0.05, 0.95))
}

```

```{r}
beta_CI
```



```{r}
# Convert log-odds to probabilities
beta_CI_prob <- plogis(beta_CI)

# Print the probability confidence intervals
print(beta_CI_prob)

```


## Alternative Specification (10 points)

With the same set of explanatory variables in your final model, estimate a linear regression model. Explain the model results; conduct model diagnostic; and assess the validity of the model assumptions. Would you use the linear regression model or binary logistic regression in this case? Explain why.

```{r}
linear_model <- lm(O.ring ~ Temp + Pressure, data = data)
summary(linear_model)
```

```{r}
plot(linear_model$fitted.values, linear_model$residuals)
```
```{r}
qqnorm(linear_model$residuals)
qqline(linear_model$residuals)
```
In this case, since the dependent variable is binary (0 or 1), it might not be appropriate to use a linear regression model. Linear regression may predict values outside the range [0,1] which doesn't make sense for a binary outcome. Instead, logistic regression, which predicts the log-odds of the outcome, might be more suitable.

# Conclusions (10 points)

Interpret the main result of your preferred model in terms of both odds and probability of failure. Summarize this result with respect to the question(s) being asked and key takeaways from the analysis.
