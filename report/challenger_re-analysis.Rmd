---
title: "W271 Group Lab 1"
subtitle: "Investigating the 1986 Space Shuttle Challenger Accident"
author: "Please fill in with your names."
output: bookdown::pdf_document2
fontsize: 11pt
geometry: margin=1in
---

\newpagecool

```{=tex}
\begin{abstract} 
This report will, indeed, be abstract. No, instead, describe your goals your approach, and what you learn.
\end{abstract}
```
# Introduction

## Research question
```{r load packages, message=FALSE}
library(car)
library(sandwich)
library(lmtest)
library(knitr)
library(Hmisc)
library(gridExtra)
library(stargazer)
library(mcprofile)
library(readr)
library(dplyr)
library(finalfit)
```

# Data (20 points)

**Complete the following task. In your final submission, please remove this question prompt so that your report reads as a report. The Data Section of this report is worth 20 points.**

-   Conduct a thorough EDA of the data set.

    -   This should include both graphical and tabular analysis as taught in this course.
    -   Since the report has a page-limit, you will have to be selective when choosing visuals to illustrate your key points, associated with a concise explanation of the visuals.

-   This EDA should begin with an inspection of the given dataset; examination of anomalies, missing values, potential of top and/or bottom code etc.

```{r}
data <- read.csv("../data/raw/challenger.csv")
data
```


```{r}
summary(data)
```

```{r}
describe(data)
```

```{r}
# Histograms
hist(data$Temp, main="Joint Temperature Distribution", xlab="Temp")
hist(data$Pressure, main="Field Leak-Pressure Distribution", xlab="Pressure")
```

```{r}
# Define colors based on O.ring values
color <- ifelse(data$O.ring > 0, "red", "green")

# Create the scatter plot
plot(data$Temp, data$O.ring, xlab = "Temperature", ylab = "O-ring", main = "Temperature vs. O-ring", pch = 19, col = color)
# Create a legend
legend("topright", legend = c("Flights with no incidents", "Number of Incidents"), col = c("green", "red"), pch = 19)

```

```{r}
data %>%
  count(O.ring) %>%
  mutate(prop = round(prop.table(n),2)) %>%
  kable(col.names = c('Incidents', 'Number', "Proportion"))
```

```{r}
plot_box = function(data,x,y,title) {
  ggplot(data, aes(factor(x), y)) +  
  geom_boxplot(aes(fill = factor(x))) + 
  geom_jitter() +
  coord_flip() +
  ggtitle(title) + 
  theme(plot.title = element_text(lineheight=1, face="bold")) 
}

# Admit and GRE
p3 <- plot_box(data, x=data$O.ring, y=data$Temp,
               title="Figure 1: O-ring incident by Temperature")

# Admit and GPA
p4 <- plot_box(data, x=data$O.ring, y=data$Pressure, 
               title="Figure 2: O-ring incident by Pressure")

grid.arrange(p3, p4, nrow = 2, ncol = 1)


```

## Description

**Complete the following task. In your final submission, please remove this question prompt so that your report reads as a report.**
 
-   Describe the data that you are using. How is this data generated, what is the sampling process that brought it to your availability. If it is helpful, you might describe the population (i.e. the Random Variables) that exist and how samples are produced from these random variables.

-   The authors use logistic regression to estimate the probability an O-ring will fail. In order to use this model, the authors needed to assume that each O-ring is independent for each launch. Discuss why this assumption is necessary and the potential problems with it. Note that a subsequent analysis helped to alleviate the authors' concerns about independence.

## Key Features

--------

# Analysis

---------

## Reproducing Previous Analysis (10 points)

**Your analysis should address the following two questions. In your final submission, please remove this question prompt so that your report reads as a report.**

1.  Estimate the logistic regression model that the authors present in their report -- include the variables as linear terms in the model. Evaluate, using likelihood ratio tests, the statistical significance of each explanatory variable in the model. Evaluate, using the context and data understanding that you have created in the **Data** section of this report, the practical significance of each explanatory variable in the model.


```{r}
# Check if O.ring is a factor, if not convert it
if (!is.factor(data$O.ring)) {
  data$O.ring <- as.factor(data$O.ring)
}

# Fit the logistic regression model
model <- glm(O.ring ~ Temp + Pressure, data = data, family = binomial(link = "logit"))

# Fit reduced models
model_temp <- glm(O.ring ~ Temp, data = data, family = binomial(link = "logit"))
model_pressure <- glm(O.ring ~ Pressure, data = data, family = binomial(link = "logit"))

summary(model)
```
The coefficient of -0.228671 indicates that for each additional degree in temperature, the log-odds of O-ring failure decrease by about 0.23, holding pressure constant. This would suggest that higher temperatures are associated with a lower risk of O-ring failure. Because the p-value (0.0376) is below 0.05, this result is statistically significant at the 5% level.

The coefficient of 0.010400 suggests that for each additional unit increase in pressure, the log-odds of O-ring failure increase by about 0.01, holding temperature constant. However, the p-value (0.2468) is greater than 0.05, suggesting that this result is not statistically significant at the 5% level. Therefore, based on this model, pressure does not have a significant effect on the log-odds of O-ring failure.

From a practical perspective, temperature seems to have a significant effect on O-ring failure, with higher temperatures reducing the likelihood of failure. However, pressure doesn't seem to significantly affect the likelihood of failure.

```{r}
# Perform likelihood ratio tests
anova(model_temp, model, test = "LRT")
```
The test compares the deviances of the two models to assess whether adding Pressure to the model significantly improves the model fit. The deviance difference (1.5331) is not statistically significant (p=0.2156), as indicated by the Pr(>Chi) value. This means that, based on this test, adding Pressure as a predictor does not significantly improve the model.

```{r}
anova(model_pressure, model, test = "LRT")
```
The test compares the deviances of the two models to assess whether adding Temp to the model significantly improves the model fit. The deviance difference (7.7542) is statistically significant (p=0.005359), as indicated by the Pr(>Chi) value. This means that adding Temp as a predictor significantly improves the model.

In summary, these results suggest that Temp is a significant predictor of O.ring failure, while Pressure is not, at least not when added to a model that already includes Temp.


```{r}
exp(coef(model))
```

The exponentiated coefficient for Temp is 0.7955903. This means that for each unit increase in Temp, the odds of O-ring failure are multiplied by approximately 0.80, or in other words, they decrease by about 20%, assuming all other variables are held constant. This matches with our previous interpretation that an increase in temperature decreases the likelihood of O-ring failure.

The exponentiated coefficient for Pressure is 1.010454. This means that for each unit increase in Pressure, the odds of O-ring failure are multiplied by approximately 1.01, or they increase by about 1%, assuming all other variables are held constant. However, remember from the earlier analysis that this effect was not statistically significant.


2.  Dalal, Fowlkes, and Hoadley (1989) chose to remove `pressure` from the model based on their likelihood ratio tests. Critically evaluate, using your test results and understanding of the question and data, whether `pressure` should be included in the model, or instead, `pressure` should not be included in the model. Your report needs to make a determination, argue why it is most appropriate choice, and make note of how (if at all) the model results are affected by the choice of including or excluding `pressure`.

Based on the likelihood ratio tests that we have conducted, we found that the inclusion of Pressure in the model does not significantly improve the model's fit when Temp is already in the model. This is indicated by a non-significant p-value (p = 0.2156) when we compared the model with Temp and Pressure to the model with Temp alone.

On the contrary, when we compared the model with Pressure alone to the model with Temp and Pressure, we observed a significant improvement in the model fit with the inclusion of Temp (p = 0.005359).

Taking these results together, it would be reasonable to exclude Pressure from the model. By doing so, we would have a simpler model that is easier to interpret, without a significant loss in predictive power.

Excluding Pressure from the model does not appear to negatively affect the model's ability to predict O-ring failure. The significant predictor, Temp, remains in the model and its coefficient remains statistically significant, indicating that it is still able to predict O-ring failure effectively.


## Confidence Intervals (20 points)

No matter what you determined about using or dropping `pressure`, for this section begin by considering the simplified model $logit(\pi) = \beta_0 + \beta_1 Temp$, where $\pi$ is the probability of an O-ring failure. Complete the following:

1.  Estimate the logistic regression model.


```{r}
model_temp <- glm(O.ring ~ Temp, family = binomial(link = "logit"), data = data)
coef(model_temp)
```

2.  Determine if a quadratic term is needed in the model for the temperature in this model.

```{r}
model_temp_quad <- glm(O.ring ~ Temp + I(Temp^2), family = binomial(link = "logit"), data = data)
anova(model_temp, model_temp_quad, test = "Chisq")

```
Not needed.

3.  Construct two plots:
4.  $\pi$ vs. Temp; and,

```{r}
temp_range <- seq(31, 81, length.out = 100)

prob_est <- predict(model_temp, newdata = data.frame(Temp = temp_range), type = "response")
conf_int <- predict(model_temp, newdata = data.frame(Temp = temp_range), type = "response", se.fit = TRUE)

conf_int_up <- plogis(conf_int$fit + 1.96 * conf_int$se.fit)
conf_int_low <- plogis(conf_int$fit - 1.96 * conf_int$se.fit)

plot(temp_range, prob_est, type = "l", xlab = "Temperature", ylab = "Probability of O-ring failure", col='red')
lines(temp_range, conf_int_low, lty = 2, col='blue')
lines(temp_range, conf_int_up, lty = 2, col='blue')
legend("bottomright", 
       legend = c("Confidence Interval", "Fitted Model"),  
       col = c("blue", "red"), 
       pch = c(20, NA),  
       lty = c(NA, 1),  
       cex = 0.8,  
       bty = "n", 
       lwd = c(NA, 2))
```

5.  Expected number of failures vs. Temp.

```{r}
expected_failures <- prob_est * 6  # Assuming there are 6 O-rings
plot(temp_range, expected_failures, type = "l", xlab = "Temperature", ylab = "Expected number of O-ring failures")
```

Specific requirements for these plots:

-   Use a temperature range of 31° to 81° on the x-axis even though the minimum temperature in the data set was 53°.\

-   Include the 95% Wald confidence interval bands for $\pi$ on the plot. Describe, in your analysis of these plots, why the bands much wider for lower temperatures than for higher temperatures?

3.  The temperature was 31° at launch for the Challenger in 1986. Estimate the probability of an O-ring failure using this temperature, and compute a corresponding confidence interval. Discuss what assumptions need to be made in order to apply the inference procedures.


```{r}
prob_31 <- predict(model_temp, newdata = data.frame(Temp = 31), type = "response")
conf_int_31 <- predict(model_temp, newdata = data.frame(Temp = 31), type = "response", se.fit = TRUE)
conf_int_31_up <- plogis(conf_int_31$fit + 1.96 * conf_int_31$se.fit)
conf_int_31_low <- plogis(conf_int_31$fit - 1.96 * conf_int_31$se.fit)

prob_31
conf_int_31_low
conf_int_31_up

```





## Bootstrap Confidence Intervals (30 points)

Rather than relying on asymptotic properties, consider using a parametric bootstrap, as did Dalal, Fowlkes and Hoadley. To do this:

1.  Simulate a large number of data sets (n = 23 for each) by re-sampling with replacement from the data.
2.  Estimate a model for each dataset.
3.  Compute the effect at a specific temperature of interest.

To produce a confidence interval, the authors used the 0.05 and 0.95 observed quantiles from the simulated distribution as their 90% confidence interval limits.

Using the parametric bootstrap, compute 90% confidence intervals separately at each integer temperature between 10° and 100° Fahrenheit.

In this section, you should describe your process, justify such a process, and present your results in a way that is compelling for your reader.

## Alternative Specification (10 points)

With the same set of explanatory variables in your final model, estimate a linear regression model. Explain the model results; conduct model diagnostic; and assess the validity of the model assumptions. Would you use the linear regression model or binary logistic regression in this case? Explain why.

# Conclusions (10 points)

Interpret the main result of your preferred model in terms of both odds and probability of failure. Summarize this result with respect to the question(s) being asked and key takeaways from the analysis.
